## 1. 프로그램 입출력 (Programmed I/O, PIO)

* **개념:** CPU가 입출력의 **모든 과정을 직접 관여**하고 제어하는 가장 기본적인 방식이다.
* **작동 방식:**
    1.  CPU가 입출력 장치(컨트롤러)의 상태 레지스터를 **반복적으로 확인**(폴링)하여 준비되었는지 검사한다.
    2.  장치가 준비되면, CPU가 직접 데이터 레지스터에서 데이터를 읽거나 쓴다.
    3.  이 과정(상태 확인 및 데이터 전송)이 완료될 때까지 CPU는 다른 작업을 하지 못하고 대기한다. (이를 **Busy-Waiting**이라 한다.)
* **장점:** 구현이 매우 간단하다.
* **단점:** CPU가 입출력이 완료될 때까지 계속 대기(폴링)해야 하므로 **CPU 낭비가 매우 심각**하다.

---

## 2. 메모리 맵 I/O vs. 고립형 I/O

이 두 가지는 CPU가 입출력 장치에 '접근(명령)'하는 방식을 구분하는 개념이다.

### ① 메모리 맵 입출력 (Memory-Mapped I/O)

* **개념:** 메모리와 입출력 장치의 레지스터를 **하나의 연속된 주소 공간**으로 취급한다.
* **특징:**
    * CPU는 특정 메모리 주소에 접근하는 것과 동일한 방식으로 입출력 장치에 접근한다.
    * 메모리 접근 명령어(예: `LOAD`, `STORE`)를 입출력에도 동일하게 사용한다.
    * 주소 공간을 공유하므로 실제 사용 가능한 메모리 영역이 줄어들 수 있다.

### ② 고립형 입출력 (Isolated I/O 또는 Port-Mapped I/O)

* **개념:** 메모리 주소 공간과 입출력 장치(포트)의 주소 공간을 **완전히 분리**하여 관리한다.
* **특징:**
    * 입출력 장치 접근을 위한 **별도의 입출력 명령어**(예: `IN`, `OUT`)를 사용한다.
    * 제어 버스에 메모리를 읽/쓰는지(Memory R/W), 입출력 포트를 읽/쓰는지(I/O R/W) 구분하는 별도의 신호선이 필요하다.
    * 메모리 주소 공간을 침범하지 않는다.

---

## 3. 인터럽트 기반 입출력 (Interrupt-driven I/O)

* **개념:** 프로그램 입출력(PIO)의 'Busy-Waiting' 문제를 해결하기 위한 방식이다. CPU가 계속 상태를 확인(폴링)하는 대신, 입출력 장치가 **작업 완료 시 CPU에게 신호**(인터럽트)를 보낸다.
* **작동 방식:**
    1.  CPU가 입출력 장치에 작업을 명령하고, 즉시 **다른 작업(프로세스)을 수행**하러 간다.
    2.  입출력 장치는 독립적으로 작업을 수행한다.
    3.  작업이 완료되면, 입출력 장치(컨트롤러)가 CPU에 **인터럽트 요청**(IRQ) 신호를 보낸다.
    4.  CPU는 현재 하던 일을 잠시 멈추고(문맥 교환), 해당 인터럽트를 처리하기 위한 **인터럽트 서비스 루틴**(ISR)을 실행한다. (예: 데이터 레지스터에서 데이터를 메모리로 옮김)
    5.  인터럽트 처리가 끝나면 원래 하던 작업으로 복귀한다.
* **장점:** PIO 방식의 **CPU 낭비(Busy-Waiting) 문제를 해결**하여 시스템 효율성을 크게 높인다.

> **폴링 (Polling):** **CPU가 주체**가 되어 입출력 장치의 상태를 **반복적으로 확인**하는 방식이다. (PIO에서 사용)  
> **인터럽트 (Interrupt):** **장치가 주체**가 되어 작업 완료를 CPU에게 **신호하는** 방식이다.

---

## 4. DMA (Direct Memory Access) 입출력

* **개념:** 인터럽트 방식의 단점(데이터 전송 자체는 여전히 CPU가 관여)을 개선한 방식이다. 대량의 데이터를 전송할 때, **CPU의 개입 없이** DMA 컨트롤러라는 특수 하드웨어가 **입출력 장치와 메모리 간의 데이터 전송을 직접** 담당한다.
* **작동 방식:**
    1.  CPU는 DMA 컨트롤러에게 작업에 필요한 정보(데이터 위치, 전송할 크기, 입출력 장치 주소 등)를 설정하고 작업을 명령한다.
    2.  CPU는 즉시 **다른 작업을 수행**하러 간다.
    3.  **DMA 컨트롤러**가 시스템 버스 사용 권한을 (CPU로부터 잠시) 받아, 입출력 장치와 메모리 간의 데이터 전송을 **블록 단위**로 직접 수행한다. (이때 CPU는 버스를 사용하지 못할 수 있으며, 이를 '사이클 스틸링'이라 부른다.)
    4.  요청된 데이터 전송이 **모두 완료**되면, DMA 컨트롤러가 CPU에 **인터럽트를 한 번만** 발생시켜 작업 완료를 알린다.
* **장점:**
    * 대용량 데이터 전송 시 CPU의 부담을 획기적으로 줄여준다. (CPU는 데이터 전송 작업에서 완전히 해방됨)
    * 인터럽트 발생 횟수를 '블록 당 1회'로 최소화하여 CPU 효율을 극대화한다.

---
---

## 백엔드 개발자를 위한 심화 인사이트

자바(JVM) 위에서 코드를 작성하므로 하드웨어의 인터럽트나 DMA를 직접 제어하지 않는다. 대신 **운영체제**(OS 커널)에 "파일 읽어줘(System Call)"라고 요청하며, 이때 OS가 사용하는 하드웨어 I/O 방식이 우리가 사용하는 **Java I/O 모델의 성능을 결정**한다.

### 1. 인터럽트 방식과 Blocking I/O

백엔드 개발자가 가장 흔하게 사용하는 `java.io` (예: `FileInputStream.read()`)가 바로 **블로킹(Blocking) I/O** 모델이다.

* **동작 과정:**
    1.  자바 스레드가 `read()` 메소드를 호출한다. (System Call 발생)
    2.  OS 커널은 이 요청을 받아 디스크 컨트롤러(DMA 사용)에게 데이터 전송을 명령한다.
    3.  이때, 커널은 PIO 방식처럼 CPU를 낭비하며 폴링(Busy-Waiting)하지 않는다. 대신, 해당 **자바 스레드를 'Blocked(대기)' 상태로 만든다.** (CPU 자원 회수)
    4.  CPU는 즉시 다른 스레드(다른 요청 처리)를 실행한다.
    5.  데이터 전송이 완료되면 하드웨어가 CPU에 **인터럽트**를 보낸다.
    6.  OS는 인터럽트를 받아 데이터 처리를 완료하고, 'Blocked' 상태였던 자바 스레드를 'Runnable(실행 가능)' 상태로 깨운다.
> 하드웨어의 **인터럽트 방식** 덕분에, OS는 하나의 스레드가 I/O를 기다리는 동안에도 CPU가 다른 스레드를 처리할 수 있도록 효율적인 **블로킹 I/O 모델**을 구현할 수 있다.

---

### 2. 논블로킹 I/O와 I/O 멀티플렉싱

스프링 WebFlux, Netty 등 현대 고성능 서버는 스레드를 대기시키지 않는 **논블로킹(Non-Blocking) I/O**를 사용한다. 이는 OS의 **'I/O 멀티플렉싱'** (예: Linux의 `epoll`) 기능을 기반으로 한다.

* **기존 방식 (스레드 1:1 대응):** 클라이언트 1만 명 접속 시, I/O 대기를 포함해 스레드 1만 개가 필요하다. (엄청난 메모리 및 컨텍스트 스위칭 비용 발생)
* **I/O 멀티플렉싱:**
    1.  **단 하나의 스레드**(이벤트 루프)가 OS 커널에 "내가 관리하는 소켓 1만 개 중에 데이터 준비된 것 있어?"라고 **한 번에** 물어본다.
    2.  OS 커널은 (하드웨어 인터럽트를 기반으로) 준비된 소켓 목록을 관리하다가, 준비된 소켓이 생기면 즉시 이벤트 루프 스레드에 "3번, 500번, 1002번 소켓 준비 완료"라고 알려준다.
    3.  이벤트 루프 스레드는 **준비된 소켓의 작업만 빠르게 처리**하고 다시 커널에 질문하러 간다.
> 이 방식은 I/O를 기다리며 '대기'(Blocked)하는 스레드가 없다. 적은 수의 스레드로 수만 개의 동시 접속을 효율적으로 처리할 수 있으며, 이는 모두 하드웨어 인터럽트가 OS 레벨에서 효율적으로 처리되기 때문에 가능하다.

---

### 3. DMA와 제로 카피

백엔드, 특히 대용량 파일 전송이나 메시지 큐(Kafka 등)에서 **성능을 극한으로 끌어올리는 핵심 기술**이 바로 DMA와 직결된 **제로 카피**이다.

* **전통적인 데이터 복사 (CPU 개입):**
    1.  [DMA] 디스크 -> **커널 버퍼**로 데이터 전송
    2.  [CPU 복사] **커널 버퍼** -> **애플리케이션(JVM) 버퍼**로 데이터 복사
    3.  [CPU 복사] **애플리케이션(JVM) 버퍼** -> **커널 소켓 버퍼**로 데이터 복사 (네트워크로 보내기 위해)
    4.  [DMA] **커널 소켓 버퍼** -> 네트워크 카드  
    ➡ 이 과정은 CPU가 관여하는 비효율적인 메모리 복사를 2번이나 수행함을 의미한다.

* **제로 카피 (Zero-Copy):** (Java NIO의 `FileChannel.transferTo()`가 대표적)
    1.  애플리케이션(JVM)이 OS 커널에 "이 파일(디스크) 내용을 저 소켓(네트워크)으로 바로 보내줘"라고 명령한다.
    2.  [DMA] 디스크 -> **커널 버퍼**로 데이터 전송
    3.  [DMA] **커널 버퍼** -> 네트워크 카드로 데이터 **직접** 전송  
    ➡ 데이터가 CPU를 거쳐 JVM 메모리 영역으로 넘어오는 과정(2, 3번)이 **완전히 생략**된다.

> **DMA** 덕분에 커널은 CPU의 개입 없이 데이터를 커널 버퍼 안에서만 전달하여 하드웨어(디스크)에서 다른 하드웨어(네트워크)로 데이터를 즉시 보낼 수 있다. 카프카(Kafka)나 Nginx 같은 고성능 서버가 압도적인 파일/데이터 전송 속도를 내는 비결 중 하나이다.
